{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4cec1fe",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f69fcd",
   "metadata": {},
   "source": [
    "- 앙상블이란 ?\n",
    "  - 여러개의 모델을 결합하여 훨씬 강력한 모델을 생성하는 기법\n",
    "  - 앙상블의 종류에는 보팅, 배깅, 부스팅, 스태킹이 있다.\n",
    "\n",
    "- 보팅\n",
    "  - 데이터를 서로 다른 알고리즘을 통해 평가하고 모든 값의 평균을 내는 것이다. 서로 다른 유형의 알고리즘으로 여러개의 모델을 만드는 것이 보팅의 특징이다.\n",
    "  - 보팅은 하드보팅과 소프트 보팅으로 나뉘는데, 하드 보팅은 모델을 통해 값을 예측하고 다수결의 원칙에 의해 값(최빈값)을 선정한다. 소프트 보팅은 0이 될 확률과 1이 될 확률을 각 각 예측하고, 비율의 평균을 따져 확률이 높은것을 선택한다. \n",
    "  \n",
    "- 배깅\n",
    "  - 서로 다른 샘플 데이터(중복을 허용하며 랜덤 추출)를 같은 알고리즘을 사용하여 여러 개의 모델을 만들어 결과를 집계하여 값을 얻는다. 중복된 샘플을 뽑는 방법을 Bootstrap (복원 랜덤 샘플링 방식이라고도 함)이라고 한다.\n",
    "  - 범주형 데이터는 투표방식으로 결과를 집계하고 연속형 데이터는 평균으로 결과를 집계한다. 보팅과 배깅을 비교했을 때, 가장 큰 차이는 같은 알고리즘을 쓰냐? 다른 알고리즘을 쓰냐?의 차이다.\n",
    "  \n",
    "- 부스팅\n",
    "  - 여러개의 알고리즘이 순차적으로 학습-예측하면서 이전에 학습한 알고리즘의 예측이 틀린 데이터를 올바르게 예측할 수 있도록, 다음 알고리즘에 가중치를 부여하고 학습과 예측하는 방식 \n",
    "  - 예측 성능이 뛰어나 앙상블 학습을 주도하며, 대표적인 부스팅 방법으로 XGBoost, LightGBM 이 있다. \n",
    "  \n",
    "- 스태킹\n",
    "  - 여러 알고리즘을 사용해 결과를 예측하고 그 결과를 새로운 최종 모델에게 예측하게 하는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0a7a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2268416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "path = 'https://raw.githubusercontent.com/jangrae/csv/master/iris.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d15b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target확인\n",
    "target ='Species'\n",
    "\n",
    "x=data.drop(target, axis=1)\n",
    "y=data.loc[:,target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74bbda94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화\n",
    "x=  (x-x.min()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95038078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 불러오기\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.3, random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d812182",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad9613e",
   "metadata": {},
   "source": [
    "### 1.KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27d0212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        14\n",
      "  versicolor       0.94      1.00      0.97        15\n",
      "   virginica       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4519e049",
   "metadata": {},
   "source": [
    "### 2.Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8e0603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0]\n",
      " [ 0 13  2]\n",
      " [ 0  1 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        14\n",
      "  versicolor       0.93      0.87      0.90        15\n",
      "   virginica       0.88      0.94      0.91        16\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.94        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=10, random_state=2022)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c43d19",
   "metadata": {},
   "source": [
    "### 3.Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24e6bd",
   "metadata": {},
   "source": [
    "- Random Forest\n",
    "  - 여러 tree가 모여있다는 의미로 랜덤 포레스트 라는 이름이 붙여졌다. 의사결정 트리는 학습 데이터에 과대적합되는 경향이 있는데 랜덤 포레스트가 이 문제를 해결할 수 있다. 샘플 데이터 100개를 만들면 중복이 생기게 되는데, 과적합을 막기위해 일부러 중복을 만든다. 같은 알고리즘을 사용하여 결과를 예측하고 값을 낸다. \n",
    "\n",
    "- 함수 : from sklearn.ensemble import RandomForestClassifier / RandomRegressor \n",
    "\n",
    "- Hyperparameter : n_estimators(트리의 개수) \n",
    "\n",
    "- Row: 랜덤하게 샘플링 \n",
    "\n",
    "- Feature : 각 tree에서 가지를 나눌 때 기준이 되는 Feature를 랜덤하게 선정 \n",
    "\n",
    "- 장점: 의사결정 트리의 쉽고 직관적인 장점, 앙상블 알고리즘 수행 속도가 비교적 빠름, 다양한 분야 좋은 성능 \n",
    "\n",
    "- 단점: 하이퍼 파라미터가 많아 튜닝을 위해 많은 시간이 소요된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fac353bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        14\n",
      "  versicolor       0.88      1.00      0.94        15\n",
      "   virginica       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(max_depth=10, random_state=2022)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a069b67",
   "metadata": {},
   "source": [
    "### 4. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395bb54",
   "metadata": {},
   "source": [
    "- XGBoost\n",
    "  - 부스팅 기법을 이용하여 구현한 알고리즘 \n",
    "- 함수 : from xgboost import XGBRegressor / XGBClassifier \n",
    "- Hyperparameter : max_depth(트리 depth 제한), n_estimators(반복 횟수) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6a8bd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[14  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        14\n",
      "  versicolor       0.88      1.00      0.94        15\n",
      "   virginica       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(max_depth=10, random_state=2022, n_estimators=20)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
